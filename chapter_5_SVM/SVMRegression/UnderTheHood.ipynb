{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c28e5a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Under the Hood\n",
    "## Decision Function and Predictions\n",
    "<img src=\"img2.png\" witdh=900 height=600 />\n",
    "$$ figure\\ 5.2\\ Decision\\ function\\ and\\ predictions $$ \n",
    "\n",
    "## Training Objective\n",
    "\n",
    "<img src='img3.png' witdh=900 height=600/>\n",
    "\n",
    "The dashed lines represent the points where the decision function is equal to 1 or –1:\n",
    "they are parallel and at equal distance to the decision boundary, forming a margin\n",
    "around it. Training a linear SVM classifier means finding the value of w and b that\n",
    "make this margin as wide as possible while avoiding margin violations (hard margin)\n",
    "or limiting them (soft margin).\n",
    "\n",
    "Consider the slope of the decision function: it is equal to the norm of the weight vec‐\n",
    "tor, ∥ w ∥. If we divide this slope by 2, the points where the decision function is equal\n",
    "to ±1 are going to be twice as far away from the decision boundary. \n",
    "\n",
    "In other words, dividing the slope by 2 will multiply the margin by 2. Perhaps this is easier to visualize in 2D:\n",
    "\n",
    "<img src='img4.png' witdh=900 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aa5d0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So we want to minimize ∥ w ∥ to get a large margin. However, if we also want to avoid any margin violation (hard margin), then we need the decision function to be greater than 1 for all positive training instances, and lower than –1 for negative training\n",
    "instances.\n",
    "\n",
    "If we define t<sup>(i)</sup> = –1 for negative instances (if y<sup>(i)</sup>  = 0) and t<sup>(i)</sup>  = 1 for positive instances (if y<sup>(i)</sup>  = 1), then we can express this constraint as t<sup>(i)</sup> (wT· x<sup>(i)</sup>  + b) ≥ 1 for allinstances.\n",
    "\n",
    "We can therefore express the hard margin linear SVM classifier objective as the con‐\n",
    "strained optimization problem.\n",
    "\n",
    "<img src='img5.png' witdh=900 height=600 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841edce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### note:\n",
    "<img src='img6.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "To get the soft margin objective, we need to introduce a slack variable ζ(i) ≥ 0 for eachinstance:4 ζ(i) measures how much the ith instance is allowed to violate the margin. We now have two conflicting objectives: making the slack variables as small as possible to reduce the margin violations, and making 1 2 wT  · w as small as possible to increase the margin. This is where the C hyperparameter comes in: it allows us to define the trade‐off between these two objectives. This gives us the constrained optimization problem\n",
    "in Equation 5-4.\n",
    "<img src='img7.png' witdh=600 height=900 />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quadratic Programming\n",
    "<img src='img8.png' />\n",
    "<img src='img9.png' />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Dual Problem\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "9d5e9b56",
   "metadata": {},
   "source": [
    "## Quadratic Programming\n",
    "<img src='img8.png' />\n",
    "<img src='img9.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223a324",
   "metadata": {},
   "source": [
    "## The Dual Problem\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}