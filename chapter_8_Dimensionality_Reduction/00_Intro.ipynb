{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d38976e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dimensionality Reduction\n",
    "Many Machine Learning problems involve thousands or even millions of features for each training instance. Not only does this make training extremely slow, it can also make it much harder to find a good solution. This problem is often referred to as the curse of dimensionality.\n",
    "\n",
    "Fortunately, in real-world problems, it is often possible to reduce the number of features considerably, turning an intractable problem into a tractable one.\n",
    "\n",
    "`Reducing dimensionality does lose some information (just like compressing an image to JPEG can degrade its quality), so even\n",
    "though it will speed up training, it may also make your system perform slightly worse. It also makes your pipelines a bit more complex and thus harder to maintain. So you should first try to train your system with the original data before considering using dimensionality reduction if training is too slow. In some cases, however, reducing the dimensionality of the training data may filter out some noise and unnecessary details and thus result in higher performance (but in general it wonâ€™t; it will just speed up training).\n",
    "`\n",
    "\n",
    "Apart from speeding up training, dimensionality reduction is also extremely useful for data visualization (or DataViz). Reducing the number of dimensions down to two (or three) makes it possible to plot a high-dimensional training set on a graph and often gain some important insights by visually detecting patterns, such as clusters.\n",
    "\n",
    "In this chapter we will discuss:\n",
    "1. The curse of dimensionality\n",
    "2. Get a sense of what goes on in high-dimensional space\n",
    "3. Present the two main approaches to dimensionality reduction (projection and Manifold Learning)\n",
    "4. three of the most popular dimensionality reduction techniques: PCA, Kernel PCA, and LLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd4d26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}