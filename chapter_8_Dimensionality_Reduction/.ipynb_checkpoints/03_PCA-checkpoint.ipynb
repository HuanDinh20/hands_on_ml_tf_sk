{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae564de8",
   "metadata": {},
   "source": [
    "# PCA\n",
    "Principal Component Analysis (PCA) is by far the most popular dimensionality reduc‐\n",
    "tion algorithm. \n",
    "\n",
    "1. First it identifies the hyperplane that lies closest to the data\n",
    "2. It projects the data onto it.\n",
    "\n",
    "## Preserving the Variance\n",
    "\n",
    "Before you can project the training set onto a lower-dimensional hyperplane, you first need to choose the right hyperplane.\n",
    "\n",
    "<img src='img_7.png'>\n",
    "\n",
    " For example, a simple 2D dataset is represented on the left of Figure 8-7, along with three different axes (i.e., one-dimensional hyperplanes). \n",
    " \n",
    " On the right is the result of the projection of the dataset onto each of these axes. As you can see, the projection onto the solid line preserves the maximum variance, while the projection onto the dotted line preserves very little variance, and the projection onto the dashed line preserves an intermediate amount of variance.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448ff24",
   "metadata": {},
   "source": [
    "It seems reasonable to select the axis that preserves the maximum amount of variance, as it will most likely lose less information than the other projections.\n",
    "\n",
    "Another way to justify this choice is that it is the axis that minimizes the mean squared distance between the original dataset and its projection onto that axis. This is the rather simple idea behind PCA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df96ed",
   "metadata": {},
   "source": [
    "## Principal Components\n",
    "\n",
    "PCA identifies the axis that accounts for the largest amount of variance in the training set.\n",
    "\n",
    "In Figure 8-7, it is the solid line. It also finds a second axis, orthogonal to the first one, that accounts for the largest amount of remaining variance. In this 2D example there is no choice: it is the dotted line. \n",
    "\n",
    "If it were a higher-dimensional data‐ set, PCA would also find a third axis, orthogonal to both previous axes, and a fourth,\n",
    "a fifth, and so on—as many axes as the number of dimensions in the dataset.\n",
    "\n",
    "The unit vector that defines the $i^{th}$ axis is called the $i^{th}$ principal component (PC).\n",
    "\n",
    "In Figure 8-7, the 1st PC is c1  and the 2nd PC is c2.\n",
    "\n",
    "`The direction of the principal components is not stable: if you perturb the training set slightly and run PCA again, some of the new PCs may point in the opposite direction of the original PCs. However, they will generally still lie on the same axes. In some cases, a pair of PCs may even rotate or swap, but the plane they define will generally remain the same.`\n",
    "\n",
    "So how can you find the principal components of a training set? Luckily, there is a standard matrix factorization technique called Singular Value Decomposition (SVD) that can decompose the training set matrix X into the dot product of three matrices U\n",
    "· Σ · $V^{T}$ , where V contains all the principal components that we are looking for\n",
    "\n",
    "<img src='img_8.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c8d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.arange(0, 100)\n",
    "X = X.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940c12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)\n",
    "U, s, Vt = np.linalg.svd(X_centered)\n",
    "c1 = Vt.T[:, 0]\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd9c6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70710678, 0.70710678])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac08f026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70710678, -0.70710678])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529ea71",
   "metadata": {},
   "source": [
    "`PCA assumes that the dataset is centered around the origin. As we will see, Scikit-Learn’s PCA classes take care of centering the data for you. However, if you implement PCA yourself, or if you use other libraries, don’t forget to center\n",
    "the data first`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09425ce8",
   "metadata": {},
   "source": [
    "## Projecting Down to d Dimensions\n",
    "\n",
    "Once you have identified all the principal components, you can reduce the dimensionality of the dataset down to d dimensions by projecting it onto the hyperplane defined by the first d principal components. Selecting this hyperplane ensures that the\n",
    "projection will preserve as much variance as possible.\n",
    "\n",
    "\n",
    "To project the training set onto the hyperplane, you can simply compute the dot product of the training set matrix X by the matrix $W_d$, defined as the matrix containing the first d principal components (i.e., the matrix composed of the first d columns of V)\n",
    "\n",
    "<img src='img_9.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6caf008",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]\n",
    "X2D = X_centered.dot(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3972020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678,  0.70710678],\n",
       "       [ 0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d6daf",
   "metadata": {},
   "source": [
    "## Using Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dcdaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X2D_sk = pca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ac3084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.70710678, -0.70710678])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_.T[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a34c93",
   "metadata": {},
   "source": [
    "### Explained Variance Ratio\n",
    "\n",
    "Another very useful piece of information is the explained variance ratio of each principal component, available via the explained_variance_ratio_ variable. It indicates the proportion of the dataset’s variance that lies along the axis of each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dec5d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 1.22347058e-33])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e6876",
   "metadata": {},
   "source": [
    "### Choosing the Right Number of Dimensions\n",
    "\n",
    "Instead of arbitrarily choosing the number of dimensions to reduce down to, it is generally preferable to choose the number of dimensions that add up to a sufficiently large portion of the variance.\n",
    "\n",
    "Unless, of course, you are reducing dimensionality for data visualization—in that case you will generally want to reduce the\n",
    "dimensionality down to 2 or 3.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e88ec",
   "metadata": {},
   "source": [
    "The following code computes PCA without reducing dimensionality, then computes\n",
    "the minimum number of dimensions required to preserve 95% of the training set’s\n",
    "variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39094e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672726f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(d.shape)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd787f",
   "metadata": {},
   "source": [
    "You could then set n_components=d and run PCA again. However, there is a much\n",
    "better option: instead of specifying the number of principal components you want to\n",
    "preserve, you can set n_components to be a float between 0.0 and 1.0, indicating the\n",
    "ratio of variance you wish to preserve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f424934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69988d5f",
   "metadata": {},
   "source": [
    "<img src='img_10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc764633",
   "metadata": {},
   "source": [
    "### PCA for Compression\n",
    "Obviously after dimensionality reduction, the training set takes up much less space.\n",
    "For example, try applying PCA to the MNIST dataset while preserving 95% of its var‐\n",
    "iance. You should find that each instance will have just over 150 features, instead of\n",
    "the original 784 features. So while most of the variance is preserved, the dataset is\n",
    "now less than 20% of its original size! This is a reasonable compression ratio, and you\n",
    "can see how this can speed up a classification algorithm (such as an SVM classifier)\n",
    "tremendously.\n",
    "\n",
    "It is also possible to decompress the reduced dataset back to 784 dimensions by\n",
    "applying the inverse transformation of the PCA projection. Of course this won’t give\n",
    "you back the original data, since the projection lost a bit of information (within the\n",
    "5% variance that was dropped), but it will likely be quite close to the original data.\n",
    "The mean squared distance between the original data and the reconstructed data\n",
    "(compressed and then decompressed) is called the reconstruction error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89edc0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X_recovered = pca.inverse_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434c20c",
   "metadata": {},
   "source": [
    "<img src='img_11.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8991f",
   "metadata": {},
   "source": [
    "### Incremental PCA\n",
    "\n",
    "One problem with the preceding implementation of PCA is that it requires the whole\n",
    "training set to fit in memory in order for the SVD algorithm to run. \n",
    "\n",
    "Incremental PCA (IPCA) algorithms have been developed: you can split the training set into mini-batches and feed an IPCA algorithm one mini-batch at a time. This is useful for large training sets, and also to apply PCA online\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a0f29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.datasets import load_diabetes\n",
    "n_batches = 9\n",
    "inc_pca = IncrementalPCA(n_components=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf58658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_diabetes()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6aa05545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c94502f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for X_batch in np.array_split(X_train, n_batches):\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "\n",
    "X_reduced = inc_pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "121bf0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (309, 9))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d0ded",
   "metadata": {},
   "source": [
    "Alternatively, you can use NumPy’s memmap class, which allows you to manipulate a large array stored in a binary file on disk as if it were entirely in memory; the class loads only the data it needs in memory, when it needs it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b8e10f",
   "metadata": {},
   "source": [
    "## Randomized PCA\n",
    "Scikit-Learn offers yet another option to perform PCA, called Randomized PCA. This is a stochastic algorithm that quickly finds an approximation of the first d principal components.\n",
    "\n",
    "s. Its computational complexity is O(m × $d^2$) + O($d^3$), instead of O(m × $n^2$)+ O($n^3$), so it is dramatically faster than the previous algorithms when d is much smaller than n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a108693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba791b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components = 152, svd_solver = 'randomized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44d66e",
   "metadata": {},
   "source": [
    "## Kernel PCA\n",
    "\n",
    "It is often good at preserving clusters of instances after projection, or sometimes even unrolling datasets that lie close to a twisted manifold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8212864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kenel_pca = KernelPCA(n_components=4, kernel='rbf', gamma=0.04)\n",
    "X_reduce = kenel_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea7a9f",
   "metadata": {},
   "source": [
    "<img src='img_13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514289f9",
   "metadata": {},
   "source": [
    "## Selecting a Kernel and Tuning Hyperparameters\n",
    "\n",
    "As kPCA is an unsupervised learning algorithm, there is no obvious performance measure to help you select the best kernel and hyperparameter values.\n",
    "\n",
    "However, dimensionality reduction is often a preparation step for a supervised learning task\n",
    "(e.g., classification), so you can simply use grid search to select the kernel and hyper‐\n",
    "parameters that lead to the best performance on that task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14b9ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5194bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('kpca', KernelPCA(n_components=2)),\n",
    "               ('logistic', LogisticRegression())])\n",
    "params = [{\n",
    "    \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "    \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(clf, params, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d54fd74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;kpca&#x27;, KernelPCA(n_components=2)),\n",
       "                                       (&#x27;logistic&#x27;, LogisticRegression())]),\n",
       "             param_grid=[{&#x27;kpca__gamma&#x27;: array([0.03      , 0.03222222, 0.03444444, 0.03666667, 0.03888889,\n",
       "       0.04111111, 0.04333333, 0.04555556, 0.04777778, 0.05      ]),\n",
       "                          &#x27;kpca__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;sigmoid&#x27;]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;kpca&#x27;, KernelPCA(n_components=2)),\n",
       "                                       (&#x27;logistic&#x27;, LogisticRegression())]),\n",
       "             param_grid=[{&#x27;kpca__gamma&#x27;: array([0.03      , 0.03222222, 0.03444444, 0.03666667, 0.03888889,\n",
       "       0.04111111, 0.04333333, 0.04555556, 0.04777778, 0.05      ]),\n",
       "                          &#x27;kpca__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;sigmoid&#x27;]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;kpca&#x27;, KernelPCA(n_components=2)),\n",
       "                (&#x27;logistic&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KernelPCA</label><div class=\"sk-toggleable__content\"><pre>KernelPCA(n_components=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('kpca', KernelPCA(n_components=2)),\n",
       "                                       ('logistic', LogisticRegression())]),\n",
       "             param_grid=[{'kpca__gamma': array([0.03      , 0.03222222, 0.03444444, 0.03666667, 0.03888889,\n",
       "       0.04111111, 0.04333333, 0.04555556, 0.04777778, 0.05      ]),\n",
       "                          'kpca__kernel': ['rbf', 'sigmoid']}])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e52b7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kpca__gamma': 0.03, 'kpca__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98446165",
   "metadata": {},
   "source": [
    "Another approach, this time entirely unsupervised, is to select the kernel and hyperparameters that yield the lowest reconstruction error. However, reconstruction is not as easy as with linear PCA.\n",
    "\n",
    "<img src='img_14.png'>\n",
    "\n",
    "Here’s why. Figure 8-11 shows the original Swiss roll 3D dataset (top left), and the resulting 2D dataset after kPCA is applied using an RBF kernel (top right). Thanks to the kernel trick, this is mathematically equivalent to mapping the training set to an infinite-dimensional feature space (bottom right) using the feature map φ, then projecting the transformed training set down to 2D using linear PCA.\n",
    "\n",
    "Notice that if we could invert the linear PCA step for a given instance in the reduced space, the reconstructed point would lie in feature space, not in the original space (e.g., like the one represented by an x in the diagram)\n",
    "\n",
    "Since the feature space is infinite-dimensional, we cannot compute the reconstructed point, and therefore we cannot compute the true reconstruction error. Fortunately, it is possible to find a point in the original space that would map close to the reconstructed point. This is called the reconstruction pre-image. Once you have this pre-image, you can measure its squared distance to the original instance. You can then select the kernel and hyperparameters that minimize this reconstruction pre-image error\n",
    "\n",
    " Scikit-Learn will do this automatically if you set\n",
    "fit_inverse_transform=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaa3ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components=2, kernel='rbf', gamma=0.03, fit_inverse_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eeb8ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = rbf_pca.fit_transform(X_train)\n",
    "X_preimage = rbf_pca.inverse_transform(X_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea821ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0022399911335444812"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(X_train, X_preimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc6f07",
   "metadata": {},
   "source": [
    "Now you can use grid search with cross-validation to find the kernel and hyperpara‐\n",
    "meters that minimize this pre-image reconstruction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05134a4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec3d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
